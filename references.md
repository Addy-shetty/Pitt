Reference Links

*   [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)


*   ChatGPT Plugin Vulnerabilities – Chat with Code Embrace the Red
*   ChatGPT Cross Plugin Request Forgery and Prompt Injection Embrace the Red
*   Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection Arxiv
*   Defending ChatGPT against Jailbreak Attack via Self-Reminder Research Square
*   Prompt Injection attack against LLM-integrated Applications Cornell University
*   Inject My PDF: Prompt Injection for your Resume Kai Greshake
*   Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection Cornell University
*   Threat Modeling LLM Applications AI Village
*   Reducing The Impact of Prompt Injection Attacks Through Design Kudelski Security
*   Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations (nist.gov)
*   2407.07403 A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends (arxiv.org)
*   Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks
*   Universal and Transferable Adversarial Attacks on Aligned Language Models (arxiv.org)
*   From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy (arxiv.org)
