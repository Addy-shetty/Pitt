# Social Media Captions for PITT

Here are a few options tailored for different platforms.

### For LinkedIn (Professional & Detailed)

**Option 1 (Achievement-focused):**

> Thrilled to announce the open-source release of my project, **PITT**!
>
> As AI and LLMs become more integrated into our applications, securing them is a top priority. To help with this challenge, I've built PITT, a command-line tool that automates security testing against the **OWASP Top 10 for Large Language Models**.
>
> Key Features:
> âœ… Comprehensive tests for prompt injection, data leakage, and more.
> âœ… Intelligent analysis using a "Judge LLM" for highly accurate results.
> âœ… Easy to configure and extend with simple YAML-based rules.
>
> This has been a passion project to deepen my skills in AI security, and I believe it can be a valuable resource for the community. I'd be honored if you'd check it out on GitHub, and I'm open to any feedback or contributions!
>
> **GitHub Link:** `[Your GitHub Repo Link Here]`
>
> \#AISecurity #LLM #ApplicationSecurity #AppSec #OpenSource #CyberSecurity #Python #DevSecOps

**Option 2 (Problem/Solution-focused):**

> How do you know if your LLM application is vulnerable to prompt injection?
>
> I've been exploring this question and decided to build a solution. I'm excited to open-source **PITT**, a security testing tool specifically for the OWASP LLM Top 10. It helps developers and AppSec engineers find vulnerabilities before they become a problem.
>
> It's built with Python and uses a "Judge LLM" to intelligently analyze responses, which has proven to be much more accurate than simple keyword matching.
>
> I'm sharing this with the community to get feedback and hopefully provide a useful tool for others in the field. You can find the project on GitHub.
>
> **GitHub Link:** `[Your GitHub Repo Link Here]`
>
> \#LLMSecurity #OpenSource #AppSec #CyberSecurity #AI #DeveloperTools

---

### For Twitter (Concise & Punchy)

**Option 1 (Direct & Energetic):**

> ðŸš€ Excited to launch PITT - my open-source security scanner for LLMs!
>
> It helps you find vulnerabilities like prompt injection & data leakage based on the OWASP LLM Top 10. Features an intelligent "Judge LLM" to reduce false positives.
>
> Check it out, star the repo, and help make AI safer! ðŸ‘‡
>
> **GitHub Link:** `[Your GitHub Repo Link Here]`
>
> \#LLMSecurity #OpenSource #InfoSec #AppSec #AI #CyberSecurity

**Option 2 (Question Hook):**

> Is your LLM secure? ðŸ¤”
>
> I built PITT, an open-source tool to test for the OWASP LLM Top 10 vulnerabilities.
>
> It's a simple CLI tool to help you automate your AI security testing. Contributions welcome!
>
> **GitHub Link:** `[Your GitHub Repo Link Here]`
>
> \#Python #DevSecOps #AISecurity #InfoSec

---

### For Telegram & Reddit (Community-focused)

**For a Telegram Group:**

> Hey everyone, I just open-sourced a project I've been working on called **PITT**.
>
> It's a CLI tool to help developers and security folks test their LLM applications against the OWASP LLM Top 10. It uses a configurable "Judge LLM" to make the vulnerability detection much more accurate than simple keyword matching.
>
> Would love for you to check it out and hear what you think!
>
> **GitHub Link:** `[Your GitHub Repo Link Here]`

**For Reddit (e.g., r/cybersecurity, r/netsec, r/opensource):**

**Title:** I built and open-sourced PITT, a tool to test for the OWASP LLM Top 10 vulnerabilities.

**Body:**

> Hey everyone,
>
> For the past few weeks, I've been diving deep into the security challenges of Large Language Models. It's a fascinating and pretty new frontier, and I wanted to build something practical to help automate testing.
>
> The result is **PITT**, a Python-based CLI tool that runs a suite of tests based on the OWASP LLM Top 10.
>
> One of the big problems I ran into was getting accurate results. Simple keyword matching was full of false positives. To solve this, I added a "Judge LLM" feature, where you can use another LLM (like Gemini or an OpenAI model) to analyze the test output and make a much more nuanced decision on whether it's a real vulnerability. This has made the results way more reliable.
>
> I'm open-sourcing this because I think it could be a useful starting point for others, and I'd love to get feedback from the community on how to make it better.
>
> The code is up on GitHub. Let me know what you think, and I'm happy to answer any questions!
>
> **GitHub Link:** `[Your GitHub Repo Link Here]`
